@article{SAVAGE2021504,
 abstract = {Model-free reinforcement learning has been recently investigated for use in chemical process control. Through the iterative creation of an approximate process model, control actions are able to be explored and optimal policies generated. Typically, this approximate process model has taken the form of a neural network that is continuously updated. However when small quantities of historical data are available, for example in novel processes, neural networks tend to over-fit to data providing poor performance. In this paper Gaussian processes are used as a method of function approximation to describe the action-value function of a non-isothermal semi-batch reactor. Through the use of analytical uncertainty obtained from Gaussian process predictions, trade off between exploration and exploitation is enabled, allowing for efficient generation of effective policies. Importantly Gaussian processes also enable probabilistic constraint violation to be modelled, ensuring safe constraint satisfaction throughout the learning procedure. On application to the in-silico case study, a safe, effective policy was generated utilising only 100 evaluations of process trajectory with no prior knowledge of the process dynamics. A result that would require significantly more trajectory evaluations when compared to a neural network based approach.},
 author = {Thomas Savage and Dongda Zhang and Max Mowbray and Ehecatl Antonio Del RÃ­o Chanona},
 doi = {https://doi.org/10.1016/j.ifacol.2021.08.292},
 issn = {2405-8963},
 journal = {IFAC-PapersOnLine},
 keywords = {Batch Processes, Modelling, Identification, Scheduling, Optimization},
 note = {16th IFAC Symposium on Advanced Control of Chemical Processes ADCHEM 2021},
 number = {3},
 pages = {504-509},
 title = {Model-free safe reinforcement learning for chemical processes using Gaussian processes},
 url = {https://www.sciencedirect.com/science/article/pii/S240589632101065X},
 volume = {54},
 year = {2021}
}

