@misc{mowbray_distributional_2022,
 abstract = {Reinforcement Learning (RL) has recently received significant attention from the process systems engineering and control communities. Recent works have investigated the application of RL to identify optimal scheduling decision in the presence of uncertainty. In this work, we present a RL methodology tailored to efficiently address production scheduling problems in the presence of uncertainty. We consider commonly imposed restrictions on these problems such as precedence and disjunctive constraints which are not naturally considered by RL in other contexts. Additionally, this work naturally enables the optimization of risk-sensitive formulations such as the conditional value-at-risk (CVaR), which are essential in realistic scheduling processes. The proposed strategy is investigated thoroughly in a parallel batch production environment, and benchmarked against mixed integer linear programming (MILP) strategies. We show that the policy identified by our approach is able to account for plant uncertainties in online decision-making, with expected performance comparable to existing MILP methods. Additionally, the framework gains the benefits of optimizing for risk-sensitive measures, and identifies online decisions orders of magnitude faster than the most efficient optimization approaches. This promises to mitigate practical issues and ease in handling realizations of process uncertainty in the paradigm of online production scheduling.},
 author = {Mowbray, Max and Zhang, Dongda and Chanona, Ehecatl Antonio Del Rio},
 doi = {10.48550/arXiv.2203.00636},
 file = {arXiv Fulltext PDF:/Users/busesibelkorkmaz/Zotero/storage/8CQWPXPN/Mowbray et al. - 2022 - Distributional Reinforcement Learning for Scheduli.pdf:application/pdf;arXiv.org Snapshot:/Users/busesibelkorkmaz/Zotero/storage/UUZVSSVN/2203.html:text/html},
 keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Systems and Control, J.6},
 month = {March},
 note = {arXiv:2203.00636 [cs, eess]},
 publisher = {arXiv},
 title = {Distributional Reinforcement Learning for Scheduling of Chemical Production Processes},
 url = {http://arxiv.org/abs/2203.00636},
 urldate = {2024-05-18},
 year = {2022}
}

