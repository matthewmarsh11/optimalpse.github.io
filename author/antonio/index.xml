<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>antonio | OptiML PSE</title><link>https://optimalpse.github.io/author/antonio/</link><atom:link href="https://optimalpse.github.io/author/antonio/index.xml" rel="self" type="application/rss+xml"/><description>antonio</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 07 May 2024 00:00:00 +0000</lastBuildDate><image><url>https://optimalpse.github.io/media/icon_hu5a76b0abcb7258b41069941c74c2d861_196285_512x512_fill_lanczos_center_3.png</url><title>antonio</title><link>https://optimalpse.github.io/author/antonio/</link></image><item><title>Reinforcement Learning</title><link>https://optimalpse.github.io/research/reinforcement-learning/</link><pubDate>Tue, 07 May 2024 00:00:00 +0000</pubDate><guid>https://optimalpse.github.io/research/reinforcement-learning/</guid><description>&lt;div style="text-align: justify">
Reinforcement Learning (RL) is a subfield of Artificial Intelligence (AI) which trains Machine Learning models to make optimal decisions. This is done in such a way that the model (or agent; or controller in a process engineering domain) learns how to take optimal actions as it explores the environment in which it resides.
RL has received a lot of attention, notable examples are ``machines" learning to play board games such as Go, or videogames such as DOTA 2 or Starcraft. Furthermore, game-playing is not all that RL is useful for. In previous work we have already optimized chemical processes under this same philosophy.
&lt;p>Reinforcement learning was designed to address the optimisation of stochastic dynamic systems. It so happens that in reality chemical processes are stochastic (due to process disturbances) and in many cases operated in dynamic mode. The difference with traditional RL applied in mainstream AI resides in the fact that RL is “data hungry” and does not consider constraints. This is a major drawback given that processes generally rely on much less data, while unbounded exploration (without constraints) can be dangerous or costly. This project aims to design a new RL algorithm that can be used to optimize complex chemical and biochemical processes which are still unresolved today.&lt;/p></description></item></channel></rss>